<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en">

<head>
  <meta http-equiv='Content-Type' content='text/html; charset=us-ascii'>
  <meta name='viewport' content='width=device-width, initial-scale=1'>
  <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">

  <title>Kanchan Bhale</title>
  <link rel="stylesheet" href="styles.css">
  <link rel='icon' type='image/jpg' href='images/WhatsApp Image 2026-02-19 at 06.47.05.jpeg'>
</head>

<!-- Simple Dark/Light Mode Toggle -->
<div id="theme-toggle-btn" title="Toggle dark/light mode">
  <span class="material-icons" id="themeToggleIcon">light_mode</span>
</div>


  <div id='videoModal' class='modal'>
    <div class='modal-content'>
      <span class='close-btn' onclick='closeModal()'>&times;</span>
      <video id='modalVideo' controls>
        <source src='' type='video/mp4'>
        Your browser does not support the video tag.
      </video>
    </div>
  </div>

  <br/>
  <table style='max-width: 900px; width: 90%; margin: auto;' border='0' cellspacing='0' cellpadding='0'>
    <tr>
      <td>
        <div class="main-layout">

            <div class="bio-name">
              <p>
                <name>Kanchan Bhale</name><br>
                <span style="font-size: 16px; color: #444;">kvb2117@columbia.edu</span>
              </p>
            </div>
          
          <div class="left-column">
            <div class="bio-text">
              <p align='justify'>Hi! I’m currently pursuing an M.S. in Data Science at <a href='https://datascience.columbia.edu/'>Columbia University</a>, working on multi-agent systems in the <a href='https://daplab.cs.columbia.edu/ '>DAPLab (The Data, Agents, and Processes Lab) </a> at Columbia, building the foundations for a future where AI agents safely and reliably automate complex work. I am a production-focused AI/ML engineer and I have previously worked as Data Scientist II at <a href='https://www.boeing.com/ '> The Boeing Company</a>, where I spent 3 years building enterprise-scale AI products. I’ve led LLM-powered developer tools, multi-agent systems, and RAG pipelines, and designed telemetry + auto-correction loops that improved relevance and reduced failures at scale - owning systems end-to-end from data and modeling to APIs and measurable impact.</p>
              <p align='justify'>My technical interests sit at the intersection of agentic AI, system reliability, interpretability, and real-world deployment (including safety-critical environments).</p>
              <p align='justify'>Earlier, I completed my B.Tech at <a href='https://cumminscollege.org/about-us/'>Cummins College of Engineering, Pune.</a> I am originally from India, and outside of my passion for agents, I enjoy spending time outdoors, especially playing basketball, hiking, and swimming.</p>
              <p align='justify'>I’m currently seeking Summer 2026 internships in Data Science, ML/AI Engineering, AI Platforms, and ML Software Engineering, always happy to connect about building production focused systems, collaborate on ideas, or share advice. Please feel free to get in touch!</p>
            </div>
            
            <div class="bio-links">
              <p>
                <a href='data/KanchanBhale_AI.pdf' class='btn' target="_blank"> <span class='material-icons'>picture_as_pdf</span> CV</a>
                <a href='https://www.researchgate.net/profile/Kanchan-Bhale' class='btn' target='_blank'> <span class='material-icons'>school</span> Google Scholar</a>
                <a href='https://www.linkedin.com/in/kvb2117/' class='btn' target='_blank'> <span class='material-icons'>business</span> LinkedIn</a>
                <a href='https://github.com/Kanchanbhale' class='btn' target='_blank'> <span class='material-icons'>code</span> GitHub</a>
                <a href='https://substack.com/@kanchanbhale1/posts' class='btn' target='_blank'> <span class='material-icons'>book</span> Blog</a>
              </p>
            </div>
          </div> <div class="profile-pic-container">
            <img src='images/WhatsApp Image 2026-02-19 at 06.47.05.jpeg' alt='Profile Picture'>
          </div>

        </div>
        <h2>News</h2>
        <div class="news-scroll-container">
          <table width='100%' border='0' cellspacing='0' cellpadding='2'>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Jan '26</span></td>
              <td width='90%' valign='top'>Joined the Columbia <a class='news-item-title' href=' https://daplab.cs.columbia.edu/' target='_blank'> Data Agents and Process Lab (DAPLab)</a>, focusing on agentic orchestration systems.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Jan '26</span></td>
              <td width='90%' valign='top'>Winner, Snapdragon-Qualcomm Hackathon (Multi-Agent Edge AI System) <a class='news-item-title' href='https://github.com/CampusGuard-snapdragron/CampusGuard' target='_blank'>[code]</a></td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Oct '25</span></td>
              <td width='90%' valign='top'>NVIDIA-Dell Annual AI hackathon semifinalist (top 18/600) <a class='news-item-title' href='https://github.com/Kanchanbhale/NVIDIA-Dell-Hackathon' target='_blank'>[code]</a>.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Sept '25</span></td>
              <td width='90%' valign='top'>Joined <a class='news-item-title' href='https://www.ask2.ai/' target='_blank'>Ask2.ai</a>, New York as a Student Quantitative Researcher under the guidance of Professor <a class='news-item-title' href='https://www.engineering.columbia.edu/faculty-staff/directory/ali-hirsa' target='_blank'>Ali Hirsa </a></td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Aug '25</span></td>
              <td width='90%' valign='top'> Started M.S. in Data Science at Columbia University, New York.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>May '25</span></td>
              <td width='90%' valign='top'>Our paper "<a class='news-item-title' href='https://docs.google.com/document/d/1J0YzZiMOMLVHPM78-tzcFj57euJ50N5D/edit?usp=sharing&ouid=109440842319091756070&rtpof=true&sd=true ' target='_blank'>Multilingual Large Language Model Transformer for Indigenous Languages</a>" was accepted in ACL 2025 (Vienna).</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Apr '25</span></td>
              <td width='90%' valign='top'>Our paper "<a class='news-item-title' href='https://icml.cc/' target='_blank'>Ethical Considerations When Deploying ML Systems</a>" was accepted in ICML 2025 (Under Review).</td>
            <tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>June '24</span></td>  
              <td width='90%' valign='top'>Promoted to Data Scientist II at Boeing AI Organization (ECFP)</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Aug '22</span></td>
              <td width='90%' valign='top'>Joined The Boeing Company as Data Scientist.</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>May '22</span></td>
              <td width='90%' valign='top'>Graduated from Cummins College of Engineering (B.Tech, Electronics & Telecommunication).</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>May '21</span></td>
              <td width='90%' valign='top'>Joined The Boeing Company as AI Engineer Intern (Computer Systems).</td>
            </tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Jan '21</span></td>
              <td width='90%' valign='top'>Our paper "<a class='news-item-title' href='https://drive.google.com/file/d/1XirlSOyzWdu6k-FfaYFzpCqjOAb76BNG/view' target='_blank'>Technical Analysis of Artificial Intelligence Assisted Swarm CubeSats for Active Debris Removal in LEO</a>" was published in IAC (Paris).</td>
            <tr>
            <tr>
              <td width='10%' valign='top'><span class='news-date'>Aug '19</span></td>
              <td width='90%' valign='top'>Founded first all Women’s Indian Satellite team at Cummins College - focus on AI for space applications. <a class='news-item-title' href='https://www.cumminscollege.org/wp-content/uploads/2024/04/Team-Vinidra-write-up.pdf ' target='_blank'>Satellite Launch Details</a></td>
            </tr>
          </table>
        </div>


        <table style='width: 100%; table-layout: fixed;' border='0' cellspacing='0' cellpadding='5' class='publications-table'>
          <br>

          <h2>Projects/Research</h2>
          <p>Please see my Resume or Github for a full list of work.</p>

          <div class="research-tabs">
            <button class="tab-btn active" onclick="filterPublications('all')">All</button>
            <button class="tab-btn" onclick="filterPublications('conference')">Agentic AI/RAG/LLMs</button>
            <button class="tab-btn" onclick="filterPublications('workshop')">Data Science (other)</button>
          </div>

          <tr data-type="conference">
            <td width="20%" class="pub-image">
                <img src="images/qualcomm.png" width="150"> 
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Privacy-First Edge Vision + Multi-Agent RAG Safety Triage (Snapdragon–Qualcomm Hackathon)</papertitle><br>
              <em>Python, YOLOv8, ONNX Runtime, INT8 Quantization, Edge Inference, GPT-4o-mini, Gemini Flash</em><br>
              <em>Claude Sonnet, Multi-Agent Orchestration, RAG, Typed Event Streams, Human-in-the-Loop</em>

              <div class="description">
                Built a privacy-first edge ML pipeline with INT8 YOLOv8 (ONNX Runtime) on mobile, publishing typed event streams under
                sub-100ms, offline latency constraints. Designed a control-plane multi-agent reasoning orchestration layer using heterogeneous LLMs
                (GPT-4o-mini, Gemini Flash, Claude Sonnet) to drive HITL-gated triage and escalation for safety-critical decision workflows. 
              </div>
              
              <a href="https://github.com/CampusGuard-snapdragron/CampusGuard" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Github</a>
             
           </pre></div>
              
            </td>
          </tr>

          <tr data-type="conference">
            <td width="20%" class="pub-image">
                <img src="images/bedrock.png" width="150"> 
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Autonomous Bedrock–Lambda Multi-Agent DevOps for Patch Generation + CI/CD Validation</papertitle><br>
        
              <em>AWS Bedrock, AWS Lambda, Python, GitHub API, Jira API, RAG, Vector Embeddings,</em>
              <em>Tool-Calling, CI/CD, Serverless, Multi-Agent Systems</em>

              <div class="description">
                Built a multi-agent Bedrock–Lambda DevOps system that auto-generated & validated code patches with more than 90% diff-accuracy
                and less than 3s serverless orchestration latency across GitHub/Jira workflows. Engineered an RAG-enhanced LLM CI/CD loop using
                vectorized context + multi-step tool-calling, enabling 70%+ automation of debugging, commits, and deployment tasks. 
              </div>

               
              <a href="https://github.com/Kanchanbhale" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Github</a>
             </pre></div>
            </td>
          </tr>

          <tr data-type="conference">
            <td width="20%" class="pub-image">
                <img src="images/nvidia.png" width="130"> 
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Vision Agent Fall-Risk Detection with LLM Reasoning for SOS Decisioning (NVIDIA x Dell)</papertitle><br>
             
              <em>Python, YOLOv8, Computer Vision, Pose Estimation, Temporal Inference,</em>
              <em>NVIDIA Nemotron-4 340B, Agentic Reasoning, Web App, Dell GB10</em>

              <div class="description">
                Deployed real-time YOLOv8 pipeline using pose dynamics + temporal inference, optimized on Dell GB10 large-compute hardware.
                Integrated NVIDIA Nemotron-4 340B for agentic reasoning over CV outputs, enabling autonomous SOS decisioning within web app 
              </div>

               
              <a href="https://github.com/Kanchanbhale/NVIDIA-Dell-Hackathon" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Github</a>
             </pre></div>
            </td>
          </tr>

          <tr data-type="conference">
            <td width="20%" class="pub-image">
              <img src="images/trainium.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Trainium-Accelerated Multi-Modal Agentic Task Automation with Event-Driven Routing</papertitle><br>
             
              <em>Python, AWS Trainium, Triton, CrewAI, SLM Inference, Event-Driven Router,</em> 
              <em>AWS STT, Intent Classification, Slot Filling, Automation Pipelines</em>

              <div class="description">
                Constructed a Trainium-accelerated SLM inference + event-driven context router (Python, Triton, CrewAI, AWS STT) for real-time
                multi-modal task automation, achieving 3x throughput gains, more than 85% intent/slot-filling accuracy, and a 60% lift in actionable
                task execution across voice, email, notes, and calendar streams.
              </div>
                 
              <a href="https://github.com/Kanchanbhale/mindflow" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Github</a>
             
</pre></div>
            </td>
          </tr>

<!--
          <tr data-type="conference">
            
            <td width="20%" class="pub-image">
              <img src="images/ICML_2.jpg" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Explainable Concept Generation through Vision-Language Preference Learning for Understanding Neural Networks' Internal Representations</papertitle><br>
              Aditya Taparia, <b>Som Sagar</b>, Ransalu Senanayake<br>
              <em>International Conference on Machine Learning (ICML)</em>, 2025

              <div class="description">
                We propose a Reinforcement Learning-based Preference Optimizing exploration (RLPO) method designed to generate explainable states within a classification model, enabling the discovery of interpretable states that may be difficult or impossible for humans to identify.
              </div>

              <a href="https://arxiv.org/abs/2408.13438" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a class="btn btn-publication" onclick="openModal('videos/GenXAI Video.mp4')"><span class="material-icons">play_circle</span> Video</a>
              <a href="https://github.com/aditya-taparia/RLPO" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Code</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib2')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib2" class="bibtex"><pre>@article{taparia2024explainable,
                title={Explainable Concept Generation through Vision-Language Preference Learning for Understanding Neural Networks' Internal Representations},
                author={Taparia, Aditya and Sagar, Som and Senanayake, Ransalu},
                journal={arXiv preprint arXiv:2408.13438},
                year={2024}
              }</pre></div>
            </td>
          </tr>
-->
          <tr data-type="workshop">
            <td width="20%" class="pub-image">
              <img src="images/charity.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>NLP-Driven Charity Recommendation Engine + Streamlit Web App (Givetastic Sponsored Capstone)</papertitle><br>
              
              <em>Python, NLP, scikit-learn, Naive Bayes, Logistic Regression, SVM, SGD, Random Forest</em> 
              <em>Streamlit, Web Scraping, Model Evaluation</em>
              <div class="description">
                Deployed a NLP-driven Charity Recommendation Engine using scraped Charity Navigator data; engineered class-balanced 
                training pipelines across Naive Bayes, Logistic Regression, SVMs, and SGD, achieving up to 98.3\% accuracy after fine-tuning.
   
              <a href="https://github.com/Kanchanbhale/LLM-NLP-Charity-Recommendation-Engine" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Github</a>
             </pre></div>
            </td>
          </tr>

          <tr data-type="workshop">
            <td width="20%" class="pub-image">
              <img src="images/ask2.ai.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>Rolling HMM Regime Detection + Regime-Aware Explainability for Macro Transition Prediction</papertitle><br>
              
              <em>Python, Hidden Markov Models, Rolling Regime Detection, Hungarian Label Alignment</em> 
              <em>Percentile Expansion Rules, Decision Trees, SHAP, Quantitative Finance, Time Series Modeling</em>
              <span style="color: #EF5350; font-weight: 600;"> &mdash; spotlight (top 3.5%)</span>
              <div class="description">
                Built a dynamic R2-RD rolling HMM regime detector that adapts over time, fixing label switching using Hungarian alignment and confidence expansion. 
                Improved explainability with regime-specific decision trees and SHAP to interpret transitions and key drivers.
              </div>
   
              <a href="https://github.com/Kanchanbhale" class="btn btn-publication" target="_blank"><span class="material-icons">code</span> Github</a>
             </pre></div>
            </td>
          </tr>
<!--
          <tr data-type="workshop">
            <td width="20%" class="pub-image">
              <img src="images/Neurips_Behaviour.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>ExpressivityArena: Can LLMs Express Information Implicitly?</papertitle><br>
              Joshua Tint, <b>Som Sagar</b>, Aditya Taparia, Caleb Liu, Kelly Raines, Bimsara Pathiraja, Ransalu Senanayake<br>
              <em>NeurIPS Workshop on Behavioral Machine Learning</em>, 2024

              <div class="description">
                We introduce ExpressivityArena, a framework designed to evaluate the expressiveness of large language models (LLMs), enabling systematic assessment of their ability to convey nuanced and implicit information across various contexts.
              </div>

              <a href="https://arxiv.org/abs/2411.08010" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib5')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib5" class="bibtex"><pre>@inproceedings{tint2024expressivityarena,
            title={ExpressivityArena: Can LLMs Express Information Implicitly?},
            author={Tint, Joshua and Sagar, Som and Taparia, Aditya and Liu, Caleb and Raines, Kelly and Pathiraja, Bimsara and Senanayake, Ransalu},
            booktitle={NeurIPS 2024 Workshop on Behavioral Machine Learning},
            year={2024}
          }</pre></div>
            </td>
          </tr>

          <tr data-type="workshop">
            <td width="20%" class="pub-image">
              <img src="images/Neurips_redteaming.png" width="150">
            </td>
            <td width="70%" valign="top" class="pub-details">
              <papertitle>LLM-Assisted Red Teaming of Diffusion Models through "Failures Are Fated, But Can Be Faded"</papertitle><br>
              <b>Som Sagar</b>, Aditya Taparia, Ransalu Senanayake<br>
              <em>NeurIPS Workshop on Red Teaming GenAI</em>, 2024

              <div class="description">
                This extension of the Failures Are Fated work demonstrates how we use LLM-assisted methods to generate rewards and states in diffusion models, and incorporate RL search strategies to optimize the discovery process.
              </div>

              <a href="https://arxiv.org/abs/2410.16738" class="btn btn-publication" target="_blank"><span class="material-icons">picture_as_pdf</span> PDF</a>
              <a href="javascript:void(0)" class="btn btn-publication" onclick="toggleBib('bib6')"><span class="material-icons">format_quote</span> BibTeX</a>
              <div id="bib6" class="bibtex"><pre>@inproceedings{sagar2024llm,
            title={LLM-Assisted Red Teaming of Diffusion Models through “Failures Are Fated, But Can Be Faded”},
            author={Sagar, Som and Taparia, Aditya and Senanayake, Ransalu},
            booktitle={Red Teaming GenAI: What Can We Learn from Adversaries?},
            year={2024}
          }</pre></div>
            </td>
          </tr>
-->
        </table>
      </td>
    </tr>
  </table>

  <br>

  <center>
    <p style="font-size: small;">Website template from <a href="https://github.com/jonbarron/jonbarron.github.io">here.</a></p>
  </center>
  

  <script>
    function toggleBib(id) { document.getElementById(id).classList.toggle('show'); }
    function openModal(src) {
      var modal = document.getElementById('videoModal');
      var videoEl = document.getElementById('modalVideo');
      videoEl.querySelector('source').src = src; videoEl.load(); modal.style.display = 'flex';
    }
    function closeModal() {
      var modal = document.getElementById('videoModal');
      var videoEl = document.getElementById('modalVideo');
      videoEl.pause(); modal.style.display = 'none';
    }
    document.getElementById('videoModal').addEventListener('click', function (e) {
      if (e.target === this) closeModal();
    });

  const toggleBtn = document.getElementById('theme-toggle-btn');
  const toggleIcon = document.getElementById('themeToggleIcon');

  // Apply stored preference
  if (localStorage.getItem('theme') === 'dark') {
    document.body.classList.add('dark');
    toggleIcon.textContent = 'dark_mode';
  }

  toggleBtn.addEventListener('click', () => {
    document.body.classList.toggle('dark');
    const isDark = document.body.classList.contains('dark');
    toggleIcon.textContent = isDark ? 'dark_mode' : 'light_mode';
    localStorage.setItem('theme', isDark ? 'dark' : 'light');
  });

  function filterPublications(type) {
    const rows = document.querySelectorAll('.publications-table tr[data-type]');
    const tabs = document.querySelectorAll('.tab-btn');
    
    // Update active tab
    tabs.forEach(tab => {
      if (tab.textContent.toLowerCase() === type) {
        tab.classList.add('active');
      } else {
        tab.classList.remove('active');
      }
    });
    
    // Filter publications
    rows.forEach(row => {
      if (type === 'all' || row.getAttribute('data-type') === type) {
        row.style.display = '';
      } else {
        row.style.display = 'none';
      }
    });
  }
  </script>
</body>

</html>
